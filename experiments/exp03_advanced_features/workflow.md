# TICKET-008-02: ç‹¬ç«‹æ€§ã®é«˜ã„é«˜æ¬¡ç‰¹å¾´é‡ - ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¬ã‚¤ãƒ‰

## ğŸ“‹ æ¦‚è¦
TICKET-008-02ã§å®Ÿè£…ã—ãŸ18å€‹ã®é«˜æ¬¡ç‰¹å¾´é‡ã‚’æ´»ç”¨ã—ã€BPMäºˆæ¸¬ç²¾åº¦ã®æ›´ãªã‚‹å‘ä¸Šã‚’å›³ã‚‹å®Ÿé¨“

---

## ğŸš€ Step 1: é«˜æ¬¡ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆ

### æ¨å¥¨ã‚³ãƒãƒ³ãƒ‰ï¼ˆãƒ•ãƒ«æ©Ÿèƒ½ç‰ˆï¼‰
```bash
# ã‚¸ãƒ£ãƒ³ãƒ«ç‰¹å¾´é‡ + å¤šé‡å…±ç·šæ€§é™¤å» + é«˜æ¬¡ç‰¹å¾´é‡ã®ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
python -m src.features --create-genre --remove-multicollinearity --create-advanced --output-dir=data/processed
```

### ç”Ÿæˆã•ã‚Œã‚‹é«˜æ¬¡ç‰¹å¾´é‡ï¼ˆ18å€‹ï¼‰

#### 1. æ¯”ç‡ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡ï¼ˆ4å€‹ï¼‰
- `vocal_energy_ratio`: VocalContent / Energyï¼ˆãƒœãƒ¼ã‚«ãƒ«é‡è¦–åº¦ï¼‰
- `acoustic_loudness_ratio`: AcousticQuality / AudioLoudnessï¼ˆéŸ³éŸ¿å“è³ªå¯¾éŸ³é‡æ¯”ï¼‰
- `rhythm_duration_ratio`: RhythmScore / log(TrackDurationMs)ï¼ˆæ™‚é–“è£œæ­£ãƒªã‚ºãƒ ï¼‰
- `instrumental_live_ratio`: InstrumentalScore / LivePerformanceLikelihoodï¼ˆæ¥½å™¨æ€§å¯¾ãƒ©ã‚¤ãƒ–æ€§ï¼‰

#### 2. å¯¾æ•°å¤‰æ›æ™‚é–“ç‰¹å¾´é‡ï¼ˆ4å€‹ï¼‰
- `log_duration_rhythm`: log(TrackDurationMs) Ã— RhythmScore
- `log_duration_energy`: log(TrackDurationMs) Ã— Energy
- `log_duration_mood`: log(TrackDurationMs) Ã— MoodScore
- `duration_category`: æ™‚é–“ã®3æ®µéšã‚«ãƒ†ã‚´ãƒªï¼ˆ0=çŸ­, 1=ä¸­, 2=é•·ï¼‰

#### 3. æ¨™æº–åŒ–æ¸ˆã¿äº¤äº’ä½œç”¨ç‰¹å¾´é‡ï¼ˆ5å€‹ï¼‰
- `standardized_vocal_mood`: zscore(VocalContent) Ã— zscore(MoodScore)
- `standardized_energy_rhythm`: zscore(Energy) Ã— zscore(RhythmScore)
- `standardized_acoustic_loudness`: zscore(AcousticQuality) Ã— zscore(AudioLoudness)
- `standardized_vocal_energy`: zscore(VocalContent) Ã— zscore(Energy)
- `standardized_rhythm_mood`: zscore(RhythmScore) Ã— zscore(MoodScore)

#### 4. éŸ³æ¥½ç†è«–ãƒ™ãƒ¼ã‚¹è¤‡é›‘æŒ‡æ¨™ï¼ˆ5å€‹ï¼‰
- `tempo_complexity`: (RhythmScore Ã— AcousticQuality) / Energy
- `performance_dynamics`: LivePerformanceLikelihood Ã— InstrumentalScore
- `music_density`: (AudioLoudness Ã— VocalContent Ã— InstrumentalScore) / log(TrackDurationMs)
- `harmonic_complexity`: (AcousticQuality Ã— MoodScore) / Energy
- `song_structure_indicator`: RhythmScore Ã— log(TrackDurationMs) Ã— LivePerformanceLikelihood

### æŠ€è¡“çš„ç‰¹å¾´
- **ã‚¼ãƒ­é™¤ç®—å¯¾ç­–**: ã™ã¹ã¦ã®é™¤ç®—ã§1e-8ã‚’åŠ ç®—
- **ç‹¬ç«‹æ€§ä¿è¨¼**: Z-scoreæ­£è¦åŒ–ã«ã‚ˆã‚‹å¤šé‡å…±ç·šæ€§å›é¿
- **éŸ³æ¥½ç†è«–ãƒ™ãƒ¼ã‚¹**: BPMäºˆæ¸¬ã«ç‰¹åŒ–ã—ãŸéŸ³æ¥½çš„è¤‡é›‘æ€§æŒ‡æ¨™

---

## ğŸ¯ Step 2: ãƒ¢ãƒ‡ãƒ«è¨“ç·´ï¼ˆé«˜æ¬¡ç‰¹å¾´é‡ä½¿ç”¨ï¼‰

### ã‚³ãƒãƒ³ãƒ‰
```bash
# é«˜æ¬¡ç‰¹å¾´é‡ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§LightGBMè¨“ç·´
python -m src.modeling.train \
    --train-path=data/processed/train_features.csv \
    --val-path=data/processed/validation_features.csv \
    --exp-name=advanced_features_lgb
```

### æœŸå¾…ã•ã‚Œã‚‹ç‰¹å¾´é‡æ§‹æˆ
- **å…ƒç‰¹å¾´é‡**: 9å€‹
- **ã‚¸ãƒ£ãƒ³ãƒ«ç‰¹å¾´é‡**: 3å€‹ï¼ˆballad, dance, acoustic_genre_scoreï¼‰
- **åŸºæœ¬ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°**: äº¤äº’ä½œç”¨ã€æ™‚é–“ã€çµ±è¨ˆç‰¹å¾´é‡
- **é«˜æ¬¡ç‰¹å¾´é‡**: 18å€‹ï¼ˆæ–°è¦è¿½åŠ ï¼‰
- **å¤šé‡å…±ç·šæ€§é™¤å»å¾Œ**: æœ€é©åŒ–ã•ã‚ŒãŸç‰¹å¾´é‡ã‚»ãƒƒãƒˆ

---

## ğŸ“Š Step 3: æ€§èƒ½è©•ä¾¡ãƒ»åˆ†æ

### 3.1 ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒ
```bash
# ç¾åœ¨ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆTICKET-008-01çµæœï¼‰
echo "ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ LB: 26.3879ï¼ˆå¤šé‡å…±ç·šæ€§é™¤å»ç‰ˆï¼‰"

# é«˜æ¬¡ç‰¹å¾´é‡ç‰ˆã®çµæœç¢ºèª
python -c "
import pandas as pd
submission = pd.read_csv('data/processed/submission_advanced_features.csv')
print(f'äºˆæ¸¬æ•°: {len(submission)}')
print(f'äºˆæ¸¬ç¯„å›²: [{submission[\"BeatsPerMinute\"].min():.2f}, {submission[\"BeatsPerMinute\"].max():.2f}]')
print(f'äºˆæ¸¬å¹³å‡: {submission[\"BeatsPerMinute\"].mean():.2f}')
"
```

### 3.2 ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ
```bash
# é«˜æ¬¡ç‰¹å¾´é‡ã®é‡è¦åº¦ç¢ºèª
python -c "
import pandas as pd
importance_df = pd.read_csv('data/processed/feature_importance_all.csv')
advanced_features = importance_df[importance_df['feature_name'].str.contains('ratio|log_duration|standardized|tempo|performance|music|harmonic|song')]
print('=== é«˜æ¬¡ç‰¹å¾´é‡é‡è¦åº¦ Top 10 ===')
print(advanced_features.head(10)[['feature_name', 'average_importance']])
"
```

### 3.3 å¤šé‡å…±ç·šæ€§åŠ¹æœç¢ºèª
```bash
# å¤šé‡å…±ç·šæ€§é™¤å»ã®åŠ¹æœåˆ†æ
cat data/processed/multicollinearity_impact_results.json
```

---

## ğŸ¯ Step 4: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬

### ã‚³ãƒãƒ³ãƒ‰
```bash
# é«˜æ¬¡ç‰¹å¾´é‡ç‰ˆã§ã®äºˆæ¸¬å®Ÿè¡Œ
python -m src.modeling.predict \
    --test-features-path=data/processed/test_features.csv \
    --exp-name=advanced_features_lgb \
    --output-path=data/processed/submission_advanced_features.csv
```

### äºˆæ¸¬çµæœã®å“è³ªç¢ºèª
```bash
# äºˆæ¸¬å€¤ã®åˆ†å¸ƒç¢ºèª
python -c "
import pandas as pd
import numpy as np
submission = pd.read_csv('data/processed/submission_advanced_features.csv')
bpm = submission['BeatsPerMinute']
print(f'äºˆæ¸¬çµ±è¨ˆ:')
print(f'  å¹³å‡: {bpm.mean():.2f}')
print(f'  æ¨™æº–åå·®: {bpm.std():.2f}')
print(f'  ç¯„å›²: [{bpm.min():.2f}, {bpm.max():.2f}]')
print(f'  ç•°å¸¸å€¤(<50 or >200): {((bpm < 50) | (bpm > 200)).sum()}')
"
```

---

## ğŸ“ˆ Step 5: å®Ÿé¨“çµæœã®è¨˜éŒ²ã¨åˆ†æ

### 5.1 experiment_results.csvæ›´æ–°
```bash
# å®Ÿé¨“çµæœCSVã«æ–°ã—ã„è¡Œã‚’è¿½åŠ 
python -c "
import pandas as pd
results_df = pd.read_csv('experiments/experiment_results.csv')

# æ–°ã—ã„å®Ÿé¨“è¡Œã‚’è¿½åŠ ï¼ˆçµæœç¢ºèªå¾Œã«å€¤ã‚’æ›´æ–°ï¼‰
new_row = {
    'exp_id': 'exp03',
    'exp_name': 'advanced_features',
    'description': 'ç‹¬ç«‹æ€§ã®é«˜ã„é«˜æ¬¡ç‰¹å¾´é‡ï¼ˆ18å€‹ï¼‰è¿½åŠ ',
    'date': '2025-09-20',
    'cv_score': 'TBD',
    'cv_std': 'TBD',
    'lb_score': 'TBD',
    'cv_lb_diff': 'TBD',
    'improvement_from_baseline': 'TBD',
    'improvement_from_previous': 'TBD',
    'model_type': 'LightGBM',
    'n_features': 'TBD',
    'n_samples': 419331,
    'cv_folds': 5,
    'training_time_min': 'TBD',
    'feature_engineering': 'æ¯”ç‡ãƒ»å¯¾æ•°ãƒ»æ¨™æº–åŒ–æ¸ˆã¿äº¤äº’ä½œç”¨ãƒ»éŸ³æ¥½ç†è«–',
    'hyperparameters': '{\"n_estimators\": 1000, \"learning_rate\": 0.1}',
    'preprocessing': 'å¤šé‡å…±ç·šæ€§é™¤å»æ¸ˆã¿',
    'ensemble_method': '5-foldå¹³å‡',
    'status': 'running',
    'submission_file': 'submission_advanced_features.csv',
    'notes': '18å€‹ã®é«˜æ¬¡ç‰¹å¾´é‡è¿½åŠ ã€‚é‡è¦ç‰¹å¾´é‡åˆ†æè¦ç¢ºèª'
}

# CSVã«è¿½åŠ 
results_df = pd.concat([results_df, pd.DataFrame([new_row])], ignore_index=True)
results_df.to_csv('experiments/experiment_results.csv', index=False)
print('experiment_results.csv ã‚’æ›´æ–°ã—ã¾ã—ãŸ')
"
```

### 5.2 exp03å®Ÿé¨“ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ•´å‚™
```bash
# å®Ÿé¨“çµæœã‚’exp03ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«æ•´ç†
mkdir -p experiments/exp03_advanced_features/{models,results}

# ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚³ãƒ”ãƒ¼ï¼ˆå®Ÿè¡Œå®Œäº†å¾Œï¼‰
cp models/advanced_features_lgb_*.pkl experiments/exp03_advanced_features/models/
cp models/advanced_features_lgb_cv_results_*.json experiments/exp03_advanced_features/results/

# æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚³ãƒ”ãƒ¼
cp data/processed/submission_advanced_features.csv experiments/exp03_advanced_features/
```

---

## ğŸ” Step 6: è©³ç´°åˆ†æã¨è€ƒå¯Ÿ

### 6.1 ç‰¹å¾´é‡ã‚«ãƒ†ã‚´ãƒªåˆ¥åŠ¹æœåˆ†æ
```bash
# ã‚«ãƒ†ã‚´ãƒªåˆ¥é‡è¦åº¦åˆ†æ
python -c "
import pandas as pd
importance_df = pd.read_csv('data/processed/feature_importance_all.csv')

categories = {
    'æ¯”ç‡ãƒ™ãƒ¼ã‚¹': 'ratio',
    'å¯¾æ•°å¤‰æ›æ™‚é–“': 'log_duration',
    'æ¨™æº–åŒ–æ¸ˆã¿äº¤äº’ä½œç”¨': 'standardized',
    'éŸ³æ¥½ç†è«–ãƒ™ãƒ¼ã‚¹': 'tempo|performance|music|harmonic|song'
}

print('=== ã‚«ãƒ†ã‚´ãƒªåˆ¥ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ ===')
for cat_name, pattern in categories.items():
    cat_features = importance_df[importance_df['feature_name'].str.contains(pattern)]
    if not cat_features.empty:
        avg_importance = cat_features['average_importance'].mean()
        top_feature = cat_features.iloc[0]['feature_name']
        print(f'{cat_name}: å¹³å‡é‡è¦åº¦={avg_importance:.4f}, ãƒˆãƒƒãƒ—={top_feature}')
"
```

### 6.2 CV-LBä¸€è²«æ€§åˆ†æ
```bash
# CVçµæœã®ç¢ºèªï¼ˆå®Ÿè¡Œå®Œäº†å¾Œï¼‰
python -c "
import json
with open('models/advanced_features_lgb_cv_results_*.json', 'r') as f:
    cv_results = json.load(f)
cv_score = cv_results['mean_rmse']
# LBã‚¹ã‚³ã‚¢ã¨æ¯”è¼ƒ
lb_score = # [å®Ÿéš›ã®LBã‚¹ã‚³ã‚¢]
consistency = abs(cv_score - lb_score)
print(f'CV-LBä¸€è²«æ€§: CV={cv_score:.4f}, LB={lb_score:.4f}, å·®={consistency:.4f}')
"
```

---

## ğŸ¯ æœŸå¾…ã•ã‚Œã‚‹æˆæœ

### å®šé‡çš„æ”¹å–„ç›®æ¨™
- **LBæ”¹å–„**: 26.3879 â†’ 26.2xï½26.3xï¼ˆ0.1-0.2ãƒã‚¤ãƒ³ãƒˆæ”¹å–„ï¼‰
- **æ”¹å–„ç‡**: 0.2-0.5%
- **ç‰¹å¾´é‡å¢—åŠ **: +18å€‹ã®é«˜æ¬¡ç‰¹å¾´é‡

### é‡è¦ç‰¹å¾´é‡äºˆæ¸¬
1. **tempo_complexity**: BPMã«ç›´çµã™ã‚‹è¤‡é›‘æ€§æŒ‡æ¨™
2. **performance_dynamics**: ãƒ©ã‚¤ãƒ–æ€§Ã—æ¥½å™¨æ€§ã®çµ„ã¿åˆã‚ã›
3. **éŸ³æ¥½å¯†åº¦ç³»ç‰¹å¾´é‡**: æ¥½æ›²ã®å¯†åº¦ã¨BPMã®é–¢ä¿‚

### æŠ€è¡“çš„ä¾¡å€¤
- **ç‹¬ç«‹æ€§ç¢ºä¿**: Z-scoreæ­£è¦åŒ–ã«ã‚ˆã‚‹å¤šé‡å…±ç·šæ€§å›é¿
- **éŸ³æ¥½ç†è«–çµ±åˆ**: ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã‚’æ´»ç”¨ã—ãŸç‰¹å¾´é‡è¨­è¨ˆ
- **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£**: ä»–ã®éŸ³æ¥½äºˆæ¸¬ã‚¿ã‚¹ã‚¯ã¸ã®å¿œç”¨å¯èƒ½æ€§

---

## ğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ãƒ¡ãƒ¢ãƒªä¸è¶³å¯¾ç­–
```bash
# å°ã‚µãƒ³ãƒ—ãƒ«ã§ã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
python -m src.features --create-advanced --output-dir=data/processed/test
```

### ç‰¹å¾´é‡æ¤œè¨¼
```bash
# ç”Ÿæˆã•ã‚ŒãŸç‰¹å¾´é‡ã®ç¢ºèª
python -c "
df = pd.read_csv('data/processed/train_features.csv')
advanced_cols = [col for col in df.columns if any(x in col for x in ['ratio', 'log_duration', 'standardized', 'tempo', 'performance', 'music', 'harmonic', 'song'])]
print(f'é«˜æ¬¡ç‰¹å¾´é‡æ•°: {len(advanced_cols)}å€‹ï¼ˆæœŸå¾…å€¤: 18å€‹ï¼‰')
if len(advanced_cols) != 18:
    print('âš  ç‰¹å¾´é‡æ•°ãŒæœŸå¾…å€¤ã¨ç•°ãªã‚Šã¾ã™')
"
```

---

**ğŸµ TICKET-008-02ã«ã‚ˆã‚Šã€éŸ³æ¥½ç†è«–ã¨çµ±è¨ˆå­¦ã‚’èåˆã—ãŸé«˜åº¦ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã§BPMäºˆæ¸¬ç²¾åº¦ã®å‘ä¸Šã‚’å®Ÿç¾ï¼**