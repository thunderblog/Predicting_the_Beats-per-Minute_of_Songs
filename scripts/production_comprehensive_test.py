#!/usr/bin/env python3
"""
æœ¬ç•ªç’°å¢ƒã§ã®åŒ…æ‹¬çš„äº¤äº’ä½œç”¨ç‰¹å¾´é‡æ€§èƒ½ãƒ†ã‚¹ãƒˆ

ç›®çš„:
- éå»ã®å®Ÿé¨“ã¨åŒç­‰ã®æ¡ä»¶ã§åŒ…æ‹¬çš„äº¤äº’ä½œç”¨ç‰¹å¾´é‡ã‚’ãƒ†ã‚¹ãƒˆ
- å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ + 5-fold CV + æœ¬æ ¼çš„LightGBMè¨­å®šã§è©•ä¾¡
- å®Ÿéš›ã®æ€§èƒ½æ”¹å–„åŠ¹æœã‚’æ­£ç¢ºã«æ¸¬å®š
"""

import sys
import pandas as pd
import numpy as np
from pathlib import Path
from loguru import logger
import lightgbm as lgb
from sklearn.model_selection import KFold
from sklearn.metrics import mean_squared_error
import warnings
import time
warnings.filterwarnings('ignore')

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
proj_root = Path(__file__).parent.parent
sys.path.append(str(proj_root))

from src.features import create_comprehensive_interaction_features
from src.config import PROCESSED_DATA_DIR

def load_full_dataset():
    """å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã‚€ï¼ˆéå»ã®å®Ÿé¨“ã¨åŒã˜æ¡ä»¶ï¼‰"""
    logger.info("å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿ä¸­...")

    train_df = pd.read_csv(PROCESSED_DATA_DIR / "train.csv")

    logger.info(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚º: {len(train_df)}ä»¶")
    logger.info(f"ç‰¹å¾´é‡æ•°: {len(train_df.columns) - 2}å€‹")  # id, BeatsPerMinuteé™¤ã

    return train_df

def production_evaluate(X, y, feature_name="Default"):
    """æœ¬ç•ªç’°å¢ƒã¨åŒç­‰ã®è¨­å®šã§ãƒ¢ãƒ‡ãƒ«è©•ä¾¡"""
    logger.info(f"æœ¬ç•ªç’°å¢ƒè©•ä¾¡é–‹å§‹: {feature_name}")

    # éå»ã®å®Ÿé¨“ã¨åŒã˜LightGBMè¨­å®š
    model_params = {
        'objective': 'regression',
        'metric': 'rmse',
        'boosting_type': 'gbdt',
        'num_leaves': 31,
        'learning_rate': 0.1,
        'feature_fraction': 0.9,
        'n_estimators': 10000,  # éå»ã®å®Ÿé¨“ã¨åŒã˜
        'verbose': -1,
        'random_state': 42
    }

    # 5-fold CVï¼ˆéå»ã®å®Ÿé¨“ã¨åŒã˜ï¼‰
    kfold = KFold(n_splits=5, shuffle=True, random_state=42)
    cv_scores = []
    fold_times = []

    logger.info(f"  ãƒ¢ãƒ‡ãƒ«è¨­å®š: 5-fold CV, n_estimators=10000, num_leaves=31")

    for fold, (train_idx, val_idx) in enumerate(kfold.split(X)):
        fold_start_time = time.time()

        X_train_fold = X.iloc[train_idx]
        X_val_fold = X.iloc[val_idx]
        y_train_fold = y.iloc[train_idx]
        y_val_fold = y.iloc[val_idx]

        # ãƒ¢ãƒ‡ãƒ«è¨“ç·´ï¼ˆEarly Stoppingä»˜ãï¼‰
        model = lgb.LGBMRegressor(**model_params)
        model.fit(
            X_train_fold, y_train_fold,
            eval_set=[(X_val_fold, y_val_fold)],
            callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]
        )

        # äºˆæ¸¬ãƒ»è©•ä¾¡
        y_pred = model.predict(X_val_fold)
        rmse = np.sqrt(mean_squared_error(y_val_fold, y_pred))
        cv_scores.append(rmse)

        fold_time = time.time() - fold_start_time
        fold_times.append(fold_time)

        logger.info(f"    Fold {fold+1}: RMSE = {rmse:.6f}, æ™‚é–“ = {fold_time:.1f}ç§’")

    avg_rmse = np.mean(cv_scores)
    std_rmse = np.std(cv_scores)
    total_time = sum(fold_times)

    logger.success(f"  {feature_name}: å¹³å‡RMSE = {avg_rmse:.6f} (Â±{std_rmse:.6f})")

    return {
        'feature_combination': feature_name,
        'n_features': X.shape[1],
        'n_samples': X.shape[0],
        'avg_rmse': avg_rmse,
        'std_rmse': std_rmse,
        'cv_scores': cv_scores,
        'total_training_time': total_time,
        'avg_fold_time': np.mean(fold_times)
    }

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•° - æœ¬ç•ªç’°å¢ƒã§ã®åŒ…æ‹¬çš„äº¤äº’ä½œç”¨ç‰¹å¾´é‡ãƒ†ã‚¹ãƒˆ"""
    logger.info("=== æœ¬ç•ªç’°å¢ƒã§ã®åŒ…æ‹¬çš„äº¤äº’ä½œç”¨ç‰¹å¾´é‡æ€§èƒ½ãƒ†ã‚¹ãƒˆ ===")

    # å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿
    full_data = load_full_dataset()
    y = full_data['BeatsPerMinute']

    # åŸºæœ¬ç‰¹å¾´é‡ï¼ˆéå»ã®å®Ÿé¨“ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼‰
    basic_features = [
        'RhythmScore', 'AudioLoudness', 'VocalContent', 'AcousticQuality',
        'InstrumentalScore', 'LivePerformanceLikelihood', 'MoodScore',
        'TrackDurationMs', 'Energy'
    ]

    results = []

    # 1. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³è©•ä¾¡ï¼ˆéå»ã®å®Ÿé¨“å†ç¾ï¼‰
    logger.info("=== 1. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³è©•ä¾¡ï¼ˆéå»ã®å®Ÿé¨“å†ç¾ï¼‰ ===")
    X_baseline = full_data[basic_features]
    baseline_result = production_evaluate(X_baseline, y, "Baselineï¼ˆåŸºæœ¬ç‰¹å¾´é‡ï¼‰")
    results.append(baseline_result)

    # 2. åŒ…æ‹¬çš„äº¤äº’ä½œç”¨ç‰¹å¾´é‡è©•ä¾¡
    logger.info("=== 2. åŒ…æ‹¬çš„äº¤äº’ä½œç”¨ç‰¹å¾´é‡è©•ä¾¡ ===")
    logger.info("åŒ…æ‹¬çš„äº¤äº’ä½œç”¨ç‰¹å¾´é‡ã‚’ç”Ÿæˆä¸­...")
    enhanced_data = create_comprehensive_interaction_features(full_data)
    feature_cols = [col for col in enhanced_data.columns if col not in ['id', 'BeatsPerMinute']]
    X_enhanced = enhanced_data[feature_cols]

    logger.info(f"ç‰¹å¾´é‡æ•°: {len(basic_features)} â†’ {len(feature_cols)}å€‹")

    enhanced_result = production_evaluate(X_enhanced, y, "åŒ…æ‹¬çš„äº¤äº’ä½œç”¨ç‰¹å¾´é‡")
    results.append(enhanced_result)

    # 3. çµæœæ¯”è¼ƒãƒ»åˆ†æ
    logger.info("=== 3. çµæœæ¯”è¼ƒãƒ»åˆ†æ ===")

    baseline_rmse = baseline_result['avg_rmse']
    enhanced_rmse = enhanced_result['avg_rmse']
    improvement = baseline_rmse - enhanced_rmse
    improvement_pct = (improvement / baseline_rmse) * 100

    logger.info(f"\\nğŸ“Š æœ¬ç•ªç’°å¢ƒã§ã®æ€§èƒ½æ¯”è¼ƒçµæœ:")
    logger.info(f"  ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³:           {baseline_rmse:.6f} (Â±{baseline_result['std_rmse']:.6f})")
    logger.info(f"  åŒ…æ‹¬çš„äº¤äº’ä½œç”¨ç‰¹å¾´é‡:   {enhanced_rmse:.6f} (Â±{enhanced_result['std_rmse']:.6f})")
    logger.info(f"  æ”¹å–„:                   {improvement:+.6f} ({improvement_pct:+.4f}%)")
    logger.info(f"  ç‰¹å¾´é‡æ•°:               {baseline_result['n_features']} â†’ {enhanced_result['n_features']}")
    logger.info(f"  ã‚µãƒ³ãƒ—ãƒ«æ•°:             {enhanced_result['n_samples']:,}ä»¶")

    # éå»ã®å®Ÿé¨“ã¨ã®æ¯”è¼ƒ
    logger.info(f"\\nğŸ” éå»ã®å®Ÿé¨“ã¨ã®æ¯”è¼ƒ:")
    logger.info(f"  éå»ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³:     26.470000 (exp01/exp005)")
    logger.info(f"  ä»Šå›ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³:     {baseline_rmse:.6f}")
    logger.info(f"  ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å·®:         {baseline_rmse - 26.47:+.6f}")

    # çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œå®š
    from scipy.stats import ttest_rel
    if len(baseline_result['cv_scores']) == len(enhanced_result['cv_scores']):
        t_stat, p_value = ttest_rel(baseline_result['cv_scores'], enhanced_result['cv_scores'])
        logger.info(f"\\nğŸ“ˆ çµ±è¨ˆçš„æœ‰æ„æ€§:")
        logger.info(f"  tçµ±è¨ˆé‡:   {t_stat:.4f}")
        logger.info(f"  på€¤:       {p_value:.6f}")
        logger.info(f"  æœ‰æ„æ€§:    {'æœ‰æ„' if p_value < 0.05 else 'æœ‰æ„ã§ã¯ãªã„'} (Î±=0.05)")

    # çµæœä¿å­˜
    import json
    results_summary = {
        'test_conditions': {
            'environment': 'production',
            'sample_size': enhanced_result['n_samples'],
            'cv_folds': 5,
            'lgbm_n_estimators': 10000,
            'early_stopping_rounds': 50
        },
        'baseline_result': baseline_result,
        'enhanced_result': enhanced_result,
        'improvement_analysis': {
            'absolute_improvement': improvement,
            'percentage_improvement': improvement_pct,
            'statistical_significance': p_value if 'p_value' in locals() else None
        },
        'comparison_with_past_experiments': {
            'past_baseline_rmse': 26.47,
            'current_baseline_rmse': baseline_rmse,
            'baseline_consistency': abs(baseline_rmse - 26.47) < 0.01
        }
    }

    results_file = Path("results/production_comprehensive_test.json")
    results_file.parent.mkdir(exist_ok=True)

    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(results_summary, f, indent=2, ensure_ascii=False, default=str)

    logger.success(f"æœ¬ç•ªç’°å¢ƒãƒ†ã‚¹ãƒˆçµæœã‚’ä¿å­˜: {results_file}")

    # çµè«–ãƒ»æ¨å¥¨äº‹é …
    logger.info(f"\\nğŸ’¡ çµè«–ãƒ»æ¨å¥¨äº‹é …:")
    if improvement > 0 and improvement_pct > 0.1:
        logger.success("âœ… åŒ…æ‹¬çš„äº¤äº’ä½œç”¨ç‰¹å¾´é‡ãŒæœ¬ç•ªç’°å¢ƒã§æœ‰åŠ¹ã«æ©Ÿèƒ½ã—ã¦ã„ã¾ã™ï¼")
        logger.info(f"ğŸ“ æ¨å¥¨: æ¬¡ã®å®Ÿé¨“ã§åŒ…æ‹¬çš„äº¤äº’ä½œç”¨ç‰¹å¾´é‡ã‚’æ¨™æº–çš„ã«ä½¿ç”¨")
        logger.info(f"ğŸ“ æœŸå¾…LBã‚¹ã‚³ã‚¢: ~{enhanced_rmse:.2f} (æ”¹å–„: {improvement_pct:+.2f}%)")
    elif abs(improvement) < 0.01:
        logger.warning("âš ï¸ æ”¹å–„åŠ¹æœã¯å¾®å°ã§ã™ã€‚ç‰¹å¾´é‡é¸æŠã¨ã®çµ„ã¿åˆã‚ã›ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
    else:
        logger.warning("âŒ åŒ…æ‹¬çš„äº¤äº’ä½œç”¨ç‰¹å¾´é‡ã®åŠ¹æœãŒç¢ºèªã§ãã¾ã›ã‚“ã§ã—ãŸ")
        logger.info("ğŸ“ æ¨å¥¨: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°æ‰‹æ³•ã®è¦‹ç›´ã—")

    return results_summary

if __name__ == "__main__":
    main()