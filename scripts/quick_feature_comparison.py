#!/usr/bin/env python3
"""
ç‰¹å¾´é‡çµ„ã¿åˆã‚ã›ã®è¿…é€Ÿæ¯”è¼ƒã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ç›®çš„:
- åŒ…æ‹¬çš„äº¤äº’ä½œç”¨ç‰¹å¾´é‡ã¨å„çµ„ã¿åˆã‚ã›ã®åŠ¹æœã‚’å°ã‚µãƒ³ãƒ—ãƒ«ã§æ¯”è¼ƒ
- è¤‡æ•°ã®çµ„ã¿åˆã‚ã›ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä¸€æ‹¬ãƒ†ã‚¹ãƒˆ
- æœ€é©ãªçµ„ã¿åˆã‚ã›ã‚’åŠ¹ç‡çš„ã«ç‰¹å®š
"""

import sys
import pandas as pd
import numpy as np
from pathlib import Path
from loguru import logger
import lightgbm as lgb
from sklearn.model_selection import KFold
from sklearn.metrics import mean_squared_error
import warnings
import time
warnings.filterwarnings('ignore')

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
proj_root = Path(__file__).parent.parent
sys.path.append(str(proj_root))

from src.features import (
    create_comprehensive_interaction_features,
    create_music_genre_features,
    create_statistical_features,
    create_interaction_features,
    create_duration_features
)
from src.config import PROCESSED_DATA_DIR

def load_quick_sample(sample_size: int = 500):
    """è¿…é€Ÿãƒ†ã‚¹ãƒˆç”¨ã®å°ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
    logger.info(f"è¿…é€Ÿãƒ†ã‚¹ãƒˆç”¨ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­ï¼ˆã‚µã‚¤ã‚º: {sample_size}ï¼‰...")

    train_df = pd.read_csv(PROCESSED_DATA_DIR / "train.csv")

    # å°ã‚µãƒ³ãƒ—ãƒ«æŠ½å‡º
    if len(train_df) > sample_size:
        sample_df = train_df.sample(n=sample_size, random_state=42)
    else:
        sample_df = train_df

    logger.info(f"ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†: {len(sample_df)}ä»¶")
    return sample_df

def quick_evaluate(X, y, feature_name="Default"):
    """è¶…è»½é‡2-fold CVã§ç‰¹å¾´é‡ã®æ€§èƒ½ã‚’è©•ä¾¡"""

    # è¶…è»½é‡LightGBMè¨­å®š
    model_params = {
        'objective': 'regression',
        'metric': 'rmse',
        'boosting_type': 'gbdt',
        'num_leaves': 15,  # ã•ã‚‰ã«è»½é‡åŒ–
        'learning_rate': 0.1,
        'n_estimators': 30,  # è»½é‡åŒ–
        'verbose': -1,
        'random_state': 42
    }

    # 2-fold CVï¼ˆè¶…è»½é‡ï¼‰
    kfold = KFold(n_splits=2, shuffle=True, random_state=42)
    cv_scores = []

    for train_idx, val_idx in kfold.split(X):
        X_train_fold = X.iloc[train_idx]
        X_val_fold = X.iloc[val_idx]
        y_train_fold = y.iloc[train_idx]
        y_val_fold = y.iloc[val_idx]

        # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
        model = lgb.LGBMRegressor(**model_params)
        model.fit(X_train_fold, y_train_fold)

        # äºˆæ¸¬ãƒ»è©•ä¾¡
        y_pred = model.predict(X_val_fold)
        rmse = np.sqrt(mean_squared_error(y_val_fold, y_pred))
        cv_scores.append(rmse)

    avg_rmse = np.mean(cv_scores)
    return {
        'feature_combination': feature_name,
        'n_features': X.shape[1],
        'avg_rmse': avg_rmse,
        'cv_scores': cv_scores
    }

def test_feature_combinations(sample_data):
    """å„ç‰¹å¾´é‡çµ„ã¿åˆã‚ã›ã‚’ãƒ†ã‚¹ãƒˆ"""

    results = []
    y = sample_data['BeatsPerMinute']

    # åŸºæœ¬ç‰¹å¾´é‡
    basic_features = [
        'RhythmScore', 'AudioLoudness', 'VocalContent', 'AcousticQuality',
        'InstrumentalScore', 'LivePerformanceLikelihood', 'MoodScore',
        'TrackDurationMs', 'Energy'
    ]

    logger.info("=== ç‰¹å¾´é‡çµ„ã¿åˆã‚ã›æ¯”è¼ƒé–‹å§‹ ===")

    # 1. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆåŸºæœ¬ç‰¹å¾´é‡ã®ã¿ï¼‰
    logger.info("1. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆåŸºæœ¬ç‰¹å¾´é‡ï¼‰ã‚’ãƒ†ã‚¹ãƒˆä¸­...")
    start_time = time.time()
    X_baseline = sample_data[basic_features]
    result_baseline = quick_evaluate(X_baseline, y, "1. Baselineï¼ˆåŸºæœ¬ç‰¹å¾´é‡ï¼‰")
    result_baseline['processing_time'] = time.time() - start_time
    results.append(result_baseline)
    logger.info(f"   RMSE: {result_baseline['avg_rmse']:.4f}, ç‰¹å¾´é‡æ•°: {result_baseline['n_features']}, æ™‚é–“: {result_baseline['processing_time']:.1f}ç§’")

    # 2. åŒ…æ‹¬çš„äº¤äº’ä½œç”¨ã®ã¿
    logger.info("2. åŒ…æ‹¬çš„äº¤äº’ä½œç”¨ç‰¹å¾´é‡ã‚’ãƒ†ã‚¹ãƒˆä¸­...")
    start_time = time.time()
    data_comprehensive = create_comprehensive_interaction_features(sample_data)
    feature_cols = [col for col in data_comprehensive.columns if col not in ['id', 'BeatsPerMinute']]
    X_comprehensive = data_comprehensive[feature_cols]
    result_comprehensive = quick_evaluate(X_comprehensive, y, "2. åŒ…æ‹¬çš„äº¤äº’ä½œç”¨ç‰¹å¾´é‡")
    result_comprehensive['processing_time'] = time.time() - start_time
    results.append(result_comprehensive)
    logger.info(f"   RMSE: {result_comprehensive['avg_rmse']:.4f}, ç‰¹å¾´é‡æ•°: {result_comprehensive['n_features']}, æ™‚é–“: {result_comprehensive['processing_time']:.1f}ç§’")

    # 3. åŒ…æ‹¬çš„äº¤äº’ä½œç”¨ + ã‚¸ãƒ£ãƒ³ãƒ«ç‰¹å¾´é‡
    logger.info("3. åŒ…æ‹¬çš„äº¤äº’ä½œç”¨ + ã‚¸ãƒ£ãƒ³ãƒ«ç‰¹å¾´é‡ã‚’ãƒ†ã‚¹ãƒˆä¸­...")
    start_time = time.time()
    data_genre = create_music_genre_features(data_comprehensive)
    feature_cols = [col for col in data_genre.columns if col not in ['id', 'BeatsPerMinute']]
    X_genre = data_genre[feature_cols]
    result_genre = quick_evaluate(X_genre, y, "3. åŒ…æ‹¬çš„äº¤äº’ä½œç”¨ + ã‚¸ãƒ£ãƒ³ãƒ«")
    result_genre['processing_time'] = time.time() - start_time
    results.append(result_genre)
    logger.info(f"   RMSE: {result_genre['avg_rmse']:.4f}, ç‰¹å¾´é‡æ•°: {result_genre['n_features']}, æ™‚é–“: {result_genre['processing_time']:.1f}ç§’")

    # 4. åŒ…æ‹¬çš„äº¤äº’ä½œç”¨ + ã‚¸ãƒ£ãƒ³ãƒ« + çµ±è¨ˆç‰¹å¾´é‡
    logger.info("4. åŒ…æ‹¬çš„äº¤äº’ä½œç”¨ + ã‚¸ãƒ£ãƒ³ãƒ« + çµ±è¨ˆç‰¹å¾´é‡ã‚’ãƒ†ã‚¹ãƒˆä¸­...")
    start_time = time.time()
    data_stats = create_statistical_features(data_genre)
    feature_cols = [col for col in data_stats.columns if col not in ['id', 'BeatsPerMinute']]
    X_stats = data_stats[feature_cols]
    result_stats = quick_evaluate(X_stats, y, "4. åŒ…æ‹¬çš„äº¤äº’ä½œç”¨ + ã‚¸ãƒ£ãƒ³ãƒ« + çµ±è¨ˆ")
    result_stats['processing_time'] = time.time() - start_time
    results.append(result_stats)
    logger.info(f"   RMSE: {result_stats['avg_rmse']:.4f}, ç‰¹å¾´é‡æ•°: {result_stats['n_features']}, æ™‚é–“: {result_stats['processing_time']:.1f}ç§’")

    # 5. åŒ…æ‹¬çš„äº¤äº’ä½œç”¨ + ã‚¸ãƒ£ãƒ³ãƒ« + çµ±è¨ˆ + æ™‚é–“ç‰¹å¾´é‡
    logger.info("5. åŒ…æ‹¬çš„äº¤äº’ä½œç”¨ + ã‚¸ãƒ£ãƒ³ãƒ« + çµ±è¨ˆ + æ™‚é–“ç‰¹å¾´é‡ã‚’ãƒ†ã‚¹ãƒˆä¸­...")
    start_time = time.time()
    data_duration = create_duration_features(data_stats)
    feature_cols = [col for col in data_duration.columns if col not in ['id', 'BeatsPerMinute']]
    X_duration = data_duration[feature_cols]
    result_duration = quick_evaluate(X_duration, y, "5. åŒ…æ‹¬çš„äº¤äº’ä½œç”¨ + ã‚¸ãƒ£ãƒ³ãƒ« + çµ±è¨ˆ + æ™‚é–“")
    result_duration['processing_time'] = time.time() - start_time
    results.append(result_duration)
    logger.info(f"   RMSE: {result_duration['avg_rmse']:.4f}, ç‰¹å¾´é‡æ•°: {result_duration['n_features']}, æ™‚é–“: {result_duration['processing_time']:.1f}ç§’")

    # 6. åŸºæœ¬äº¤äº’ä½œç”¨ã®ã¿ï¼ˆæ¯”è¼ƒç”¨ï¼‰
    logger.info("6. åŸºæœ¬äº¤äº’ä½œç”¨ç‰¹å¾´é‡ï¼ˆæ¯”è¼ƒç”¨ï¼‰ã‚’ãƒ†ã‚¹ãƒˆä¸­...")
    start_time = time.time()
    data_basic_interaction = create_interaction_features(sample_data)
    feature_cols = [col for col in data_basic_interaction.columns if col not in ['id', 'BeatsPerMinute']]
    X_basic_interaction = data_basic_interaction[feature_cols]
    result_basic_interaction = quick_evaluate(X_basic_interaction, y, "6. åŸºæœ¬äº¤äº’ä½œç”¨ç‰¹å¾´é‡ï¼ˆæ¯”è¼ƒç”¨ï¼‰")
    result_basic_interaction['processing_time'] = time.time() - start_time
    results.append(result_basic_interaction)
    logger.info(f"   RMSE: {result_basic_interaction['avg_rmse']:.4f}, ç‰¹å¾´é‡æ•°: {result_basic_interaction['n_features']}, æ™‚é–“: {result_basic_interaction['processing_time']:.1f}ç§’")

    return results

def analyze_results(results):
    """çµæœã‚’åˆ†æã—ã¦æœ€é©ãªçµ„ã¿åˆã‚ã›ã‚’ç‰¹å®š"""
    logger.info("=== çµæœåˆ†æ ===")

    # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’åŸºæº–ã¨ã—ãŸæ”¹å–„ç‡è¨ˆç®—
    baseline_rmse = results[0]['avg_rmse']

    logger.info("\nğŸ“Š æ€§èƒ½æ¯”è¼ƒçµæœ:")
    logger.info(f"{'çµ„ã¿åˆã‚ã›':<35} {'RMSE':<8} {'æ”¹å–„ç‡':<8} {'ç‰¹å¾´é‡æ•°':<8} {'æ™‚é–“':<6}")
    logger.info("-" * 75)

    best_result = None
    best_improvement = -float('inf')

    for result in results:
        improvement = baseline_rmse - result['avg_rmse']
        improvement_pct = (improvement / baseline_rmse) * 100

        logger.info(f"{result['feature_combination']:<35} "
                   f"{result['avg_rmse']:<8.4f} "
                   f"{improvement_pct:+6.2f}% "
                   f"{result['n_features']:<8} "
                   f"{result['processing_time']:<6.1f}ç§’")

        if improvement > best_improvement:
            best_improvement = improvement
            best_result = result

    logger.info("-" * 75)
    logger.success(f"ğŸ† æœ€è‰¯ã®çµ„ã¿åˆã‚ã›: {best_result['feature_combination']}")
    logger.success(f"   RMSE: {best_result['avg_rmse']:.4f} (ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚ˆã‚Š{best_improvement:+.4f}æ”¹å–„)")
    logger.success(f"   æ”¹å–„ç‡: {(best_improvement / baseline_rmse) * 100:+.2f}%")

    # åŠ¹ç‡æ€§åˆ†æ
    logger.info("\nğŸ¯ åŠ¹ç‡æ€§åˆ†æ:")
    for result in results:
        efficiency = (baseline_rmse - result['avg_rmse']) / result['processing_time']
        logger.info(f"{result['feature_combination'][:25]:<25}: åŠ¹ç‡æ€§ = {efficiency:.6f} (æ”¹å–„/ç§’)")

    return best_result, results

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    logger.info("=== ç‰¹å¾´é‡çµ„ã¿åˆã‚ã›è¿…é€Ÿæ¯”è¼ƒãƒ†ã‚¹ãƒˆ ===")

    # å°ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    sample_data = load_quick_sample(sample_size=500)

    # å„çµ„ã¿åˆã‚ã›ã‚’ãƒ†ã‚¹ãƒˆ
    results = test_feature_combinations(sample_data)

    # çµæœåˆ†æ
    best_result, all_results = analyze_results(results)

    # çµæœä¿å­˜
    import json
    results_summary = {
        'test_conditions': {
            'sample_size': len(sample_data),
            'cv_folds': 2,
            'lgbm_n_estimators': 30
        },
        'results': all_results,
        'best_combination': best_result
    }

    results_file = Path("results/quick_feature_comparison.json")
    results_file.parent.mkdir(exist_ok=True)

    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(results_summary, f, indent=2, ensure_ascii=False)

    logger.success(f"æ¯”è¼ƒçµæœã‚’ä¿å­˜: {results_file}")

    # æ¨å¥¨äº‹é …
    logger.info("\nğŸ’¡ æ¨å¥¨äº‹é …:")
    if best_result['feature_combination'].find('åŒ…æ‹¬çš„äº¤äº’ä½œç”¨') != -1:
        logger.info("âœ… åŒ…æ‹¬çš„äº¤äº’ä½œç”¨ç‰¹å¾´é‡ãŒæœ‰åŠ¹ã§ã™ï¼")
        logger.info(f"âœ… æ¨å¥¨çµ„ã¿åˆã‚ã›: {best_result['feature_combination']}")
        logger.info("ğŸ“ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: ã‚ˆã‚Šå¤§ããªã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã§ã®æ¤œè¨¼")
    else:
        logger.warning("âš ï¸ åŒ…æ‹¬çš„äº¤äº’ä½œç”¨ç‰¹å¾´é‡ã®åŠ¹æœãŒé™å®šçš„ã§ã™")
        logger.info("ğŸ“ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã‚„ãƒ‡ãƒ¼ã‚¿å“è³ªã®ç¢ºèª")

    return results_summary

if __name__ == "__main__":
    main()