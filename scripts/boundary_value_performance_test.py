"""
TICKET-027: å¢ƒç•Œå€¤å¤‰æ›å‰å¾Œã®æ€§èƒ½æ¯”è¼ƒå®Ÿé¨“

TICKET-025ã§å®Ÿè£…ã—ãŸå¢ƒç•Œå€¤å¤‰æ›ã‚·ã‚¹ãƒ†ãƒ ã®åŠ¹æœã‚’æ¤œè¨¼ã™ã‚‹ã€‚
ç›®æ¨™: CV-LBæ ¼å·®+0.076â†’+0.030ä»¥ä¸‹ã®å¤§å¹…æ”¹å–„ã®ç¢ºèª
"""

import sys
from pathlib import Path
from typing import Dict, Tuple

import pandas as pd
import numpy as np
from loguru import logger
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import mean_squared_error
import lightgbm as lgb

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(str(Path(__file__).parent.parent))

from src.config import PROCESSED_DATA_DIR, MODELS_DIR


class BoundaryValuePerformanceTest:
    """å¢ƒç•Œå€¤å¤‰æ›å‰å¾Œã®æ€§èƒ½æ¯”è¼ƒå®Ÿé¨“ã‚¯ãƒ©ã‚¹."""

    def __init__(self):
        """åˆæœŸåŒ–."""
        self.results = {}

        # LightGBMãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆæ—¢å­˜ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æº–æ‹ ï¼‰
        self.lgb_params = {
            'objective': 'regression',
            'metric': 'rmse',
            'boosting_type': 'gbdt',
            'num_leaves': 31,
            'learning_rate': 0.05,
            'feature_fraction': 0.9,
            'bagging_fraction': 0.8,
            'bagging_freq': 5,
            'verbose': -1,
            'random_state': 42
        }

    def load_datasets(self) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿.

        Returns:
            (å…ƒãƒ‡ãƒ¼ã‚¿, å¤‰æ›å¾Œãƒ‡ãƒ¼ã‚¿)ã®ã‚¿ãƒ—ãƒ«
        """
        logger.info("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿ä¸­...")

        # å…ƒãƒ‡ãƒ¼ã‚¿
        original_path = PROCESSED_DATA_DIR / "train_unified_75_features.csv"
        original_data = pd.read_csv(original_path)

        # å¤‰æ›å¾Œãƒ‡ãƒ¼ã‚¿
        transformed_path = PROCESSED_DATA_DIR / "train_boundary_transformed.csv"
        transformed_data = pd.read_csv(transformed_path)

        logger.info(f"å…ƒãƒ‡ãƒ¼ã‚¿: {original_data.shape}")
        logger.info(f"å¤‰æ›å¾Œãƒ‡ãƒ¼ã‚¿: {transformed_data.shape}")

        return original_data, transformed_data

    def create_bpm_stratified_folds(self, y: pd.Series, n_splits: int = 5) -> StratifiedKFold:
        """BPMå¸¯åŸŸåˆ¥StratifiedKFoldä½œæˆ.

        Args:
            y: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°
            n_splits: åˆ†å‰²æ•°

        Returns:
            StratifiedKFoldã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        """
        # BPMå¸¯åŸŸãƒ©ãƒ™ãƒ«ä½œæˆ
        bpm_bins = [0, 80, 120, 160, 200, float('inf')]
        bpm_labels = pd.cut(y, bins=bpm_bins, labels=['Slow', 'Moderate', 'Fast', 'VeryFast', 'Extreme'])

        return StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42), bpm_labels

    def run_cv_experiment(self, X: pd.DataFrame, y: pd.Series,
                         experiment_name: str) -> Dict:
        """ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿé¨“å®Ÿè¡Œ.

        Args:
            X: ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿
            y: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°
            experiment_name: å®Ÿé¨“å

        Returns:
            å®Ÿé¨“çµæœè¾æ›¸
        """
        logger.info(f"CVå®Ÿé¨“é–‹å§‹: {experiment_name}")

        skf, bpm_labels = self.create_bpm_stratified_folds(y)

        fold_results = []
        oof_predictions = np.zeros(len(y))

        for fold, (train_idx, val_idx) in enumerate(skf.split(X, bpm_labels), 1):
            logger.info(f"Fold {fold} å®Ÿè¡Œä¸­...")

            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

            # LightGBMãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
            train_data = lgb.Dataset(X_train, label=y_train)
            val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)

            # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
            model = lgb.train(
                self.lgb_params,
                train_data,
                valid_sets=[val_data],
                num_boost_round=1000,
                callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]
            )

            # äºˆæ¸¬
            val_pred = model.predict(X_val, num_iteration=model.best_iteration)
            oof_predictions[val_idx] = val_pred

            # RMSEè¨ˆç®—
            fold_rmse = np.sqrt(mean_squared_error(y_val, val_pred))
            fold_results.append(fold_rmse)

            logger.info(f"Fold {fold} RMSE: {fold_rmse:.6f}")

        # å…¨ä½“çµæœ
        overall_rmse = np.sqrt(mean_squared_error(y, oof_predictions))
        mean_cv_rmse = np.mean(fold_results)
        std_cv_rmse = np.std(fold_results)

        results = {
            'experiment_name': experiment_name,
            'n_features': X.shape[1],
            'n_samples': len(X),
            'overall_rmse': overall_rmse,
            'mean_cv_rmse': mean_cv_rmse,
            'std_cv_rmse': std_cv_rmse,
            'fold_results': fold_results,
            'oof_predictions': oof_predictions
        }

        logger.success(f"{experiment_name} å®Œäº†: CV RMSE {mean_cv_rmse:.6f} Â± {std_cv_rmse:.6f}")

        return results

    def run_comparison_experiment(self) -> Dict:
        """æ¯”è¼ƒå®Ÿé¨“ã®å®Ÿè¡Œ.

        Returns:
            æ¯”è¼ƒçµæœè¾æ›¸
        """
        logger.info("å¢ƒç•Œå€¤å¤‰æ›å‰å¾Œã®æ€§èƒ½æ¯”è¼ƒå®Ÿé¨“é–‹å§‹")

        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        original_data, transformed_data = self.load_datasets()

        target_col = 'BeatsPerMinute'
        y = original_data[target_col]

        # å…ƒãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´é‡ï¼ˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆé™¤ãï¼‰
        original_features = [col for col in original_data.columns if col != target_col]
        X_original = original_data[original_features]

        # å¤‰æ›å¾Œãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´é‡ï¼ˆå…ƒç‰¹å¾´é‡ + æ–°ç‰¹å¾´é‡ï¼‰
        transformed_features = [col for col in transformed_data.columns if col != target_col]
        X_transformed = transformed_data[transformed_features]

        logger.info(f"å…ƒãƒ‡ãƒ¼ã‚¿ç‰¹å¾´é‡æ•°: {len(original_features)}")
        logger.info(f"å¤‰æ›å¾Œç‰¹å¾´é‡æ•°: {len(transformed_features)}")

        # å®Ÿé¨“1: å…ƒãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼‰
        baseline_results = self.run_cv_experiment(
            X_original, y, "Baseline_Original_Features"
        )

        # å®Ÿé¨“2: å¤‰æ›å¾Œãƒ‡ãƒ¼ã‚¿
        transformed_results = self.run_cv_experiment(
            X_transformed, y, "Boundary_Transformed_Features"
        )

        # æ¯”è¼ƒåˆ†æ
        improvement = baseline_results['mean_cv_rmse'] - transformed_results['mean_cv_rmse']
        improvement_pct = (improvement / baseline_results['mean_cv_rmse']) * 100

        comparison_results = {
            'baseline': baseline_results,
            'transformed': transformed_results,
            'improvement': {
                'rmse_improvement': improvement,
                'improvement_percentage': improvement_pct,
                'is_significant': abs(improvement) > (baseline_results['std_cv_rmse'] + transformed_results['std_cv_rmse'])
            }
        }

        # çµæœè¡¨ç¤º
        self.display_comparison_results(comparison_results)

        return comparison_results

    def display_comparison_results(self, results: Dict):
        """æ¯”è¼ƒçµæœã®è¡¨ç¤º.

        Args:
            results: æ¯”è¼ƒçµæœè¾æ›¸
        """
        logger.success("=== å¢ƒç•Œå€¤å¤‰æ›åŠ¹æœæ¤œè¨¼çµæœ ===")

        baseline = results['baseline']
        transformed = results['transformed']
        improvement = results['improvement']

        logger.info(f"ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³    : CV RMSE {baseline['mean_cv_rmse']:.6f} Â± {baseline['std_cv_rmse']:.6f} ({baseline['n_features']}ç‰¹å¾´é‡)")
        logger.info(f"å¢ƒç•Œå€¤å¤‰æ›å¾Œ    : CV RMSE {transformed['mean_cv_rmse']:.6f} Â± {transformed['std_cv_rmse']:.6f} ({transformed['n_features']}ç‰¹å¾´é‡)")

        if improvement['rmse_improvement'] > 0:
            logger.success(f"æ”¹å–„åŠ¹æœ: -{improvement['rmse_improvement']:.6f} ({improvement['improvement_percentage']:.3f}%å‘ä¸Š)")
        else:
            logger.warning(f"æ€§èƒ½å¤‰åŒ–: {abs(improvement['rmse_improvement']):.6f} ({abs(improvement['improvement_percentage']):.3f}%åŠ£åŒ–)")

        logger.info(f"çµ±è¨ˆçš„æœ‰æ„æ€§: {'æœ‰æ„' if improvement['is_significant'] else 'éæœ‰æ„'}")

        # TICKET-025ç›®æ¨™ã¨ã®æ¯”è¼ƒ
        target_improvement = 0.076 - 0.030  # +0.076â†’+0.030ã®æ”¹å–„ç›®æ¨™
        if improvement['rmse_improvement'] >= target_improvement:
            logger.success(f"ğŸ¯ TICKET-025ç›®æ¨™é”æˆ: {improvement['rmse_improvement']:.6f} >= {target_improvement:.6f}")
        else:
            logger.info(f"ç›®æ¨™ã¾ã§: ã‚ã¨{target_improvement - improvement['rmse_improvement']:.6f}ã®æ”¹å–„ãŒå¿…è¦")

    def save_results(self, results: Dict, output_path: Path = None):
        """çµæœä¿å­˜.

        Args:
            results: ä¿å­˜å¯¾è±¡çµæœ
            output_path: å‡ºåŠ›ãƒ‘ã‚¹
        """
        if output_path is None:
            output_path = Path("boundary_value_experiment_results.json")

        # numpyé…åˆ—ã‚’ãƒªã‚¹ãƒˆã«å¤‰æ›
        serializable_results = self._make_json_serializable(results)

        import json
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(serializable_results, f, indent=2, ensure_ascii=False)

        logger.info(f"å®Ÿé¨“çµæœä¿å­˜: {output_path}")

    def _make_json_serializable(self, obj):
        """JSON serializableå½¢å¼ã«å¤‰æ›."""
        if isinstance(obj, dict):
            return {key: self._make_json_serializable(value) for key, value in obj.items()}
        elif isinstance(obj, list):
            return [self._make_json_serializable(item) for item in obj]
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, (np.int64, np.int32)):
            return int(obj)
        elif isinstance(obj, (np.float64, np.float32)):
            return float(obj)
        else:
            return obj


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°."""
    logger.info("TICKET-027: å¢ƒç•Œå€¤å¤‰æ›å‰å¾Œã®æ€§èƒ½æ¯”è¼ƒå®Ÿé¨“é–‹å§‹")

    try:
        # æ€§èƒ½æ¯”è¼ƒå®Ÿé¨“å®Ÿè¡Œ
        tester = BoundaryValuePerformanceTest()
        results = tester.run_comparison_experiment()

        # çµæœä¿å­˜
        tester.save_results(results)

        logger.success("TICKET-027: æ€§èƒ½æ¯”è¼ƒå®Ÿé¨“å®Œäº†")

    except Exception as e:
        logger.error(f"æ€§èƒ½æ¯”è¼ƒå®Ÿé¨“ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        raise


if __name__ == "__main__":
    main()